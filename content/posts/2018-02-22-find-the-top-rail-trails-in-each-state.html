---
title: Finding the top rail-trails in each state using mixed effects models
author: ''
date: '2018-02-22'
slug: find-the-top-rail-trails-in-each-state
categories: [walkthrough, r]
tags: [rail-trails, multi-level-models, lme4]
description: A Shiny app web to find to top-rated rail-trails
meta_img: /images/image.jpg
---



<p>Outside of education, one of my interests is cycling, and one of my favorite ways to cycle is on rail-trails, pathways and greenways that are converted from former railroad tracks.</p>
<p>In a side-project (and because the data source can be used for teaching and learning about complex, nested data), I collected information from the <a href="https://www.traillink.com/">TrailLink website</a>. I’ve blogged about this data <a href="https://jrosen48.github.io/blog/michigan-rail-trails-and-pathways-through-data/">here</a> and <a href="https://jrosen48.github.io/blog/characteristics-of-rail-trails/">here</a> to find out what the best rail-trails in Michigan are and to find out what the characteristics of the best rail-trails are, respectively.</p>
<p>Using this data, I created a simple Shiny web app (<a href="https://jrosen48.github.io/blog/find-the-top-rail-trails-in-each-state/">here</a>) to find the top rail-trails (using the reviews from TrailLink) in each state. One neat thing about the app is that it uses predictions from a mixed effects (or multi-level) model.</p>
<p><a href = "https://jmichaelrosenberg.shinyapps.io/railtrails/
"><img src="/images/railtrails.png"></a></p>
<p>The reason I chose to do this is that using the raw reviews to find the top rail-trails is not as helpful as I first thought, as trails with very few (but very high) reviews–such as one with two “5” (out of 5) reviews–may end up ranked as the top in the state. At the same time, a trail with many (primarily high) reviews–such as one with 30 reviews that average out to almost but not quite “5”–may be ranked lower.</p>
<p>In <code>lme4</code>, the model is a random intercept (for the trail and state) model and would look like this (all of the code is <a href="https://github.com/jrosen48/railtrails/blob/master/app/app.R">here</a>):</p>
<pre class="r"><code>m1 &lt;- lmer(raw_reviews ~ 1 + (1|name) + (1|state), data = d)</code></pre>
<p>The model, which accounts for the multiple (repeated) reviews for each trail and the nesting of trails in each state looks something like this:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat { y } _{ trail,\quad state }\quad =\\ { \beta  }_{ 0 }(overall\quad mean\quad review)\quad +\\ { \alpha  }_{ 1 }{ (trail\quad effect) }_{ trail }\quad +\\ { \alpha  }_{ 2 }{ (state\quad effect) }_{ state }\quad +\\ { \varepsilon  }_{ trail,\quad state }
\end{aligned}
\]</span></p>
<p>So, the mixed effects model helps to account for both the number and variability in the reviews, giving a bit more weight to trails with a whole lot of high reviews relative to trails with less reviews to go on to (hopefully) predict rankings. In any case, you can check out the app at <a href="https://jmichaelrosenberg.shinyapps.io/railtrails/" class="uri">https://jmichaelrosenberg.shinyapps.io/railtrails/</a>.</p>

<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Using characteristics of rail-trails to predict how they are rated | Joshua M. Rosenberg, Ph.D.</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">CV</a></li>
      
      <li><a href="/categories/">Blog Categories</a></li>
      
      <li><a href="https://makingdatasciencecount.com">Research Group Website</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Using characteristics of rail-trails to predict how they are rated</span></h1>

<h2 class="date">2017/08/02</h2>
</div>



<main>



<div id="catching-up" class="section level1">
<h1>Catching up</h1>
<p>I wrote a blog post (one that, to be honest, I liked a lot) on what the best rail-trails are in Michigan (<a href="https://jrosen48.github.io/2017/07/24/michigan-rail-trails-and-pathways-through-data/">here</a>). A friend and colleague at MSU, Andy, noticed that paved trails seemed to be rated higher, and this as well as my cfriend and colleague Kristy’s comment about how we can use the output of the the previous post sparked my curiosity in trying to figure out what characteristics predict how highly (or not highly) rated trails are.</p>
<p>Let’s start the same way we did before.</p>
<pre class="r"><code>library(tidyverse)
library(lme4)
library(stringr)
library(sjPlot)
library(forcats)

f &lt;- here::here(&quot;static&quot;, &quot;data&quot;, &quot;mi.rds&quot;)
df &lt;- read_rds(f) # this is a file with the rail-trail data - you can get it from here: https://github.com/jrosen48/railtrail

df &lt;- df %&gt;% 
    unnest(raw_reviews) %&gt;% 
    filter(!is.na(raw_reviews)) %&gt;% 
    rename(raw_review = raw_reviews,
           trail_name = name) %&gt;% 
    mutate(trail_name = str_sub(trail_name, end = -7L),
           distance = str_sub(distance, end = -6L),
           distance = as.numeric(distance),
           n_reviews = str_sub(n_reviews, end = -9L),
           n_reviews = as.numeric(n_reviews))</code></pre>
<p>We’ll process the data a bit.</p>
<pre class="r"><code>df &lt;- df %&gt;% 
    mutate(category = as.factor(category),
           category = fct_recode(category, &quot;Greenway/Non-RT&quot; = &quot;Canal&quot;),
           mean_review = ifelse(mean_review == 0, NA, mean_review))

df &lt;- mutate(df,
             surface_rc = case_when(
                 surface == &quot;Asphalt&quot; ~ &quot;Paved&quot;,
                 surface == &quot;Asphalt, Concrete&quot; ~ &quot;Paved&quot;,
                 surface == &quot;Concrete&quot; ~ &quot;Paved&quot;,
                 surface == &quot;Asphalt, Boardwalk&quot; ~ &quot;Paved&quot;,
                 str_detect(surface, &quot;Stone&quot;) ~ &quot;Crushed Stone&quot;,
                 str_detect(surface, &quot;Ballast&quot;) ~ &quot;Crushed Stone&quot;,
                 str_detect(surface, &quot;Gravel&quot;) ~ &quot;Crushed Stone&quot;,
                 TRUE ~ &quot;Other&quot;
             )
)

df$surface_rc &lt;- as.factor(df$surface_rc)

df$surface_rc &lt;- fct_relevel(df$surface_rc,
                             &quot;Crushed Stone&quot;)</code></pre>
<p>Note that the other category includes surfaces like dirt and grass.</p>
</div>
<div id="the-model-we-built-take-one" class="section level1">
<h1>The model we built (take one)</h1>
<p>Previously we fit a model like this:</p>
<pre class="r"><code>m1 &lt;- lmer(raw_review ~ 1 + (1|trail_name), data = df)</code></pre>
<p>This model basically estimated the rating for each trail, taking account not only of the <code>1</code> - <code>5</code> ratings and how different they are from the “average” review across every trail. In short, it estimates ratings that are less biased by how many reviews there are.</p>
</div>
<div id="building-a-model-take-two" class="section level1">
<h1>Building a model (take two)</h1>
<p>It’s a bit boring, and to extend this, we can add the variables for surface (paved, crushed stone, or other), category (rail-trail or greenway), and distance. You can focus on the <code>B</code> in the table above. The intercept represents the overall average rating, which is <code>3.50</code>. The <code>B</code> for distance represents the increase in rating for each 1-mile increase in distance (<code>0.00</code>!). This suggests longer trails are not necessarily more highly rated, and the <code>p</code> (<code>0.895</code>) - which we use conventionally to find out whether the <code>B</code> is significant if it is below <code>0.05</code> - supports this interpretation.</p>
<p>Similarly, the <code>B</code> for rail-trail compared to greenways is small (and the <code>p</code> is far greater than <code>0.05</code>) as is the case for other surfaces compared to crushed stone (<code>B</code> = <code>-0.35</code>, <code>p</code> = <code>0.318</code>), but paved surfaces do seem different. They are associated with a rating almost half a point (<code>B</code> = <code>0.37</code>, <code>p</code> = <code>0.037</code>) higher than other trails, and almost a whole point (<code>0.72</code>) higher than other surfaces.</p>
<pre class="r"><code>m2 &lt;- lmer(raw_review ~ 1 + distance + category + surface_rc + (1|trail_name), data = df)

summary(m2)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: 
## raw_review ~ 1 + distance + category + surface_rc + (1 | trail_name)
##    Data: df
## 
## REML criterion at convergence: 7599.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.2026 -0.4539  0.1829  0.6112  2.0698 
## 
## Random effects:
##  Groups     Name        Variance Std.Dev.
##  trail_name (Intercept) 0.5349   0.7314  
##  Residual               0.8319   0.9121  
## Number of obs: 2757, groups:  trail_name, 116
## 
## Fixed effects:
##                      Estimate Std. Error t value
## (Intercept)         3.8056858  0.2156471  17.648
## distance           -0.0007626  0.0052627  -0.145
## categoryRail-Trail -0.0171616  0.1662643  -0.103
## surface_rcOther    -0.2437101  0.3393114  -0.718
## surface_rcPaved     0.4144877  0.1815039   2.284
## 
## Correlation of Fixed Effects:
##             (Intr) distnc ctgR-T srfc_O
## distance    -0.488                     
## ctgryRl-Trl -0.466 -0.267              
## srfc_rcOthr -0.403  0.253 -0.007       
## surfc_rcPvd -0.782  0.400  0.106  0.401</code></pre>
<pre class="r"><code># sjt.lmer(m2, p.kr = F, show.re.var = F, show.ci = F, show.se = T)</code></pre>
<p>Note that the arguments to <code>sjt.lmer()</code> only have to do with what output is produced.</p>
</div>
<div id="so-where-are-we-really-riding-next" class="section level1">
<h1>So, where are we (really) riding next?</h1>
<p>This suggests that if you want to ride a good rail-trail, first and foremost pick one that is paved, while whether a trail is technically a rail-trail or a greenway, and whether the trail is short or long, do not <em>seem</em> to matter. Although we will explore this more in later posts.</p>
</div>

</main>

  <footer>
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-43032207-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  
  <hr/>
  &copy; <a href="https://joshuamrosenberg.com">Joshua M. Rosenberg</a> 2015 &ndash; 2019 | <a href="https://scholar.google.com/citations?user=nxVowRQAAAAJ&amp;hl=en">Google Scholar</a> | <a href="https://github.com/jrosen48">GitHub</a> | <a href="http://orcid.org/0000-0003-2170-0447">ORCID</a> | <a href="https://osf.io/xzqbc/">OSF</a>
  
  </footer>
  </body>
</html>

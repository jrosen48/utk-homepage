<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>In what months are educational psychology jobs posted? | Joshua M. Rosenberg</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link href="//YOUR-CDN-LINK/styles/github.min.css" rel="stylesheet">
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">CV</a></li>
      
      <li><a href="/research/">Research</a></li>
      
      <li><a href="/teaching/">Teaching</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">In what months are educational psychology jobs posted?</span></h1>

<h2 class="date">2017/08/15</h2>
</div>

<main>



<p><a href="http://apadiv15.org/">Division 15</a> of the American Psychological Association sponsors the <a href="http://edpsychjobs.info/">Ed Psych Jobs</a> website, which is an excellent resource for Ed Psych job seekers. I thought it would possibly be helpful to see when jobs were posted in the past in order to have a better idea about when jobs may be posted this year.</p>
<div id="ed-psych-jobs-robots-.txt-and-paths_allowed-oh-my" class="section level1">
<h1>Ed Psych Jobs, Robots (.txt), and paths_allowed, oh my</h1>
<p>As this project involves a bit of web-scraping, I first checked the <code>robots.txt</code> file (located at <a href="http://edpsychjobs.info/robots.txt" class="uri">http://edpsychjobs.info/robots.txt</a>) to find out whether accessing any or all content in such a way was prohibited. It looks like only the log-in pages are listed as those that should not be accessed.</p>
<p>If interested, <a href="http://www.robotstxt.org/robotstxt.html">here</a> is a good resource on <code>robots.txt</code> files.</p>
<p>As a shortcut, there is a neat R package that has the function <code>paths_allowed()</code>, that takes a URL to a page on a website, returning a <code>TRUE</code> if, according to the <code>robots.txt</code> file, accessing the content available through the URL is allowed. Here is an example of using that, which confirms the manual check of the file I did (it is better to be safe than sorry with web scraping):</p>
<pre class="r"><code>library(robotstxt)
paths_allowed(&quot;http://edpsychjobs.info/category/all-jobs/&quot;)</code></pre>
<pre><code>## [1] TRUE</code></pre>
</div>
<div id="accessing-the-dates-of-posts" class="section level1">
<h1>Accessing the dates of posts</h1>
<p>Let’s get scraping. We will load a few packages and write a few lines of code to just scrape the dates (not the names of the jobs or any other information):</p>
<pre class="r"><code>library(rvest)
library(tidyverse)
library(lubridate)
library(hrbrthemes)

read_the_dates &lt;- function(page, url = &quot;http://edpsychjobs.info/category/all-jobs/page/&quot;) {
    Sys.sleep(1)
    
    results_df &lt;- tibble(
        dates = vector(length = 1)
    )
    
    base_url &lt;- paste0(url, page)
    page_html &lt;- read_html(base_url)
    date &lt;- html_nodes(page_html, &quot;.published&quot;)
    
    results_df &lt;- mutate(results_df,
                         date = list(html_text(date)))
    
    return(results_df)
}</code></pre>
<p>Notice in this code we used <code>Sys.sleep(1)</code>.</p>
<p>Although the <code>robots.txt</code> did not specify a time delay (often websites request a 10 second delay between page loads for web scrapers), this command specifies a 1 second delay between page loads, just to be considerate in terms of taking up the bandwidth of the web server.</p>
<p>I checked manually to see how many pages had job postings; there were 76, and so I’m just passing numbers 1 through 76 as arguments to the function we wrote above through the function <code>map_df()</code>, which will take care of the iteration (this is the <code>map</code> part), and output the results in a data frame (specified through the <code>df</code> part).</p>
<p><em>Just as a note</em>: Another way to do this would be to write a function that goes from page 1 up through a page number for which a page does not load. Still another way would be to use the very handy <code>possibly()</code> (from the <code>purrr</code> package) or some other function that deals with errors (in this case, a page that does not load), and specify a large range of page numbers, say, from 0 to 100.</p>
<pre class="r"><code>output_df &lt;- map_df(1:76, read_the_dates)</code></pre>
</div>
<div id="analysis" class="section level1">
<h1>Analysis</h1>
<p>Now that we have the data, we can process it a bit (note that the <code>unnest()</code> part is because we created a row in the data frame for each page, but each page contains at most six dates, so this function unnests those dates so that they would occupy six rows, instead of one).</p>
<p>Like many functions in R, this is only one way - but I think a good one! - of many that you could do to achieve the same output.</p>
<pre class="r"><code>processed_dates &lt;- output_df %&gt;% 
    select(date) %&gt;% 
    unnest(date) %&gt;% 
    mutate(date = mdy(date),
           month = month(date, label = T),
           year = year(date))</code></pre>
<p>We can now count up how many posts there are per month and look at their proportion:</p>
<pre class="r"><code>processed_dates %&gt;% 
    count(month) %&gt;% 
    mutate(proportion = round(n / sum(n), 2))</code></pre>
<pre><code>## # A tibble: 12 x 3
##    month     n proportion
##    &lt;ord&gt; &lt;int&gt;      &lt;dbl&gt;
##  1 Jan      28       0.06
##  2 Feb      22       0.05
##  3 Mar      25       0.05
##  4 Apr      27       0.06
##  5 May      31       0.07
##  6 Jun      23       0.05
##  7 Jul      21       0.05
##  8 Aug      57       0.12
##  9 Sep      77       0.17
## 10 Oct      74       0.16
## 11 Nov      42       0.09
## 12 Dec      29       0.06</code></pre>
<p>How many (and the proportion) per year:</p>
<pre class="r"><code>processed_dates %&gt;% 
    count(year) %&gt;% 
    mutate(proportion = round(n / sum(n), 2))</code></pre>
<pre><code>## # A tibble: 6 x 3
##    year     n proportion
##   &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;
## 1  2013    97       0.21
## 2  2014   113       0.25
## 3  2015    58       0.13
## 4  2016    52       0.11
## 5  2017    59       0.13
## 6  2018    77       0.17</code></pre>
<p>And look at differences between years in posts per month:</p>
<pre class="r"><code>df_plot_2 &lt;- processed_dates %&gt;% 
    count(year, month) %&gt;% 
    complete(year, month, fill = list(n = 0)) %&gt;% 
    mutate(year = as.factor(year)) %&gt;% 
    filter(!(year == 2017 &amp; month %in% c(&quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;)))

ggplot(df_plot_2, aes(x = month, y = n, group = year, color = year)) +
    geom_point(alpha = .3) +
    geom_line() +
    xlab(NULL) +
    ylab(&quot;Number of Posts&quot;) +
    ggtitle(&quot;Number of Posts / Month on EdPsychJobs&quot;)</code></pre>
<p><img src="/blog/2017-08-15-when-are-ed-psych-jobs-posted_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="what-can-we-learn-from-this" class="section level1">
<h1>What can we learn from this?</h1>
<p>Overall, the number of postings seems to align with the academic job cycle, where jobs for the <em>next</em> year are posted just around a year before their start date: You would expect an announcement for a job that has a start date of August, 2018 to be around August through October of the year before.</p>
<p>But there are many jobs posted throughout the year, too. And there appear to be differences between years. Of course, there are many possible caveats:</p>
<ul>
<li>The extent to which the jobs posted on this site are comprehensive (do they serve as a source of information about all educational psychology jobs, or is it better to think of it as a sample?)</li>
<li>There are other fields similar to educational psychology that may be worth comparing</li>
<li>These postings are for all kinds of educational psychology-related jobs - post-docs, research assistant or associate jobs, adjunct, and tenure-track</li>
<li>The analysis is completely descriptive, and you could develop a predictive model for how many jobs will be posted, say, in September and October, 2017</li>
</ul>
<p>Nevertheless, it is possibly useful. Any of this code can be used to re-create the data, improve this, or do something different with it.</p>
</div>

</main>

  <footer>
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-43032207-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>

<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>

<script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

  
  <hr/>
  &copy; <a href="https://joshuamrosenberg.com">Joshua M. Rosenberg</a> 2015 &ndash; 2018 | <a href="https://scholar.google.com/citations?user=nxVowRQAAAAJ&amp;hl=en">Google Scholar</a> | <a href="https://www.researchgate.net/profile/Joshua_Rosenberg2">ResearchGate</a> | <a href="https://github.com/jrosen48">Github</a> | <a href="https://twitter.com/jrosenberg6432">Twitter</a>
  
  </footer>
  </body>
</html>

